{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "139dca48-5cbd-472e-bae1-4e8bba356762",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pathlib\n",
    "import tempfile\n",
    "import time\n",
    "import copy\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aaa7587d-12d0-43c1-b237-52a37fec6862",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "BASE_DIR= pathlib.Path('/Volumes/pmr_dev/lead_ingots/lead_ingot_images')\n",
    "\n",
    "image_dir= BASE_DIR / 'Ingot'\n",
    "label_dir= BASE_DIR / 'Labels/Labels.csv'\n",
    "file_list = pd.read_csv(label_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbbbea89-8566-4853-8a29-45e5fc24e33a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(file_list.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d92cd5c-2df3-4904-a460-71548ed421e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the function to encode labels\n",
    "def encode_labels(file_list):\n",
    "    # Extract image names\n",
    "    image_names = file_list['Image']\n",
    "    \n",
    "    # Combine fault categories into a single label\n",
    "    # Create a label string by concatenating fault category names where the value is True\n",
    "    labels = file_list.drop(columns=['Image']).apply(\n",
    "        lambda row: '_'.join(row.index[row == True]), axis=1\n",
    "    )\n",
    "    \n",
    "    # Encode the labels using LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    encoded_labels = le.fit_transform(labels)\n",
    "    \n",
    "    # Create a dictionary mapping image names to encoded labels\n",
    "    label_dict = dict(zip(image_names, encoded_labels))\n",
    "    \n",
    "    return label_dict, le\n",
    "\n",
    "# Encode the labels\n",
    "label_dict, label_encoder = encode_labels(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01b94aba-bcb3-468a-9bec-4f591e2fd1fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Print the mapping of label numbers to fault categories\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Label Number to Fault Category Mapping:\")\n",
    "for fault_category, label_number in label_mapping.items():\n",
    "    print(f\"{label_number}: {fault_category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4110738-cbf7-46d4-b3f7-8169410306ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate and print the frequencies of the different classes\n",
    "label_counts = pd.Series(label_dict.values()).value_counts()\n",
    "print(\"Frequencies of the different classes:\")\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de822bc1-9b82-466d-b8ad-1752da8beb75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Custom Dataset Class\n",
    "class LeadIngotDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.labels = labels\n",
    "        self.images = images  \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8eb8bd9-7db7-4fe3-b62d-b9aa2e7af979",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load all images at once\n",
    "def load_images(image_names):\n",
    "    images = []\n",
    "    for image_name in image_names:\n",
    "        image_path = image_dir / image_name\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        images.append(image)\n",
    "    return images\n",
    "# Load all images\n",
    "image_names = file_list['Image'].tolist()\n",
    "images = load_images(image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "354c33fa-aa54-406c-8ba1-e88ebcc988f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d08af588-4f56-4881-a42f-1a10b5368130",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), #alexnet, vgg16 input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) #imagenet noramlization\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d109c6a-df06-45f7-a420-586b4915313c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "labels = [label_dict[img] for img in image_names]\n",
    "dataset = LeadIngotDataset(images, labels, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84e9080a-ff0c-4893-9869-c0f35f3c91bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "batch_size= 32\n",
    "\n",
    "# Filter images and labels to include only label 7\n",
    "filtered_indices = [i for i, label in enumerate(labels) if label == 7]\n",
    "filtered_images = [images[i] for i in filtered_indices]\n",
    "filtered_labels = [labels[i] for i in filtered_indices]\n",
    "\n",
    "dataset = LeadIngotDataset(filtered_images,filtered_labels, transform)\n",
    "\n",
    "train_val_indices, test_indices = train_test_split(\n",
    "    range(len(dataset)), test_size=0.2, stratify=filtered_labels, random_state=42\n",
    ")\n",
    "\n",
    "# Then split train+val into train and validation sets\n",
    "train_indices, val_indices = train_test_split(\n",
    "    train_val_indices, test_size=0.125, stratify=[filtered_labels[i] for i in train_val_indices], random_state=42\n",
    ")\n",
    "\n",
    "# Create Subset datasets\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "# Print statistics\n",
    "train_labels = [filtered_labels[i] for i in train_indices]\n",
    "val_labels = [filtered_labels[i] for i in val_indices]\n",
    "test_labels = [filtered_labels[i] for i in test_indices]\n",
    "\n",
    "print(f\"Train set size: {len(train_dataset)} frequenties: {torch.bincount(torch.tensor(train_labels))}\")\n",
    "print(f\"Validation set size: {len(val_dataset)} frequenties: {torch.bincount(torch.tensor(val_labels))}\")\n",
    "print(f\"Test set size: {len(test_dataset)} frequenties: {torch.bincount(torch.tensor(test_labels))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7541336b-e5cc-4acb-8183-943fc505f5ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class UNetAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=2, padding=1),  # -> N, 16, 112, 112\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),  # -> N, 32, 56, 56\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.encoder3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),  # -> N, 64, 28, 28\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.encoder4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),  # -> N, 128, 14, 14\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.encoder5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, stride=2, padding=1),  # -> N, 256, 7, 7\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        self.decoder5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1),  # -> N, 128, 14, 14\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),  # -> N, 64, 28, 28\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 32, 3, stride=2, padding=1, output_padding=1),  # -> N, 32, 56, 56\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 16, 3, stride=2, padding=1, output_padding=1),  # -> N, 16, 112, 112\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 3, 3, stride=2, padding=1, output_padding=1),  # -> N, 3, 224, 224\n",
    "            nn.Sigmoid()  # Ensure output is in range [0, 1]\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Encoding\n",
    "        enc1 = self.encoder1(x)  # -> N, 16, 112, 112\n",
    "        enc2 = self.encoder2(enc1)  # -> N, 32, 56, 56\n",
    "        enc3 = self.encoder3(enc2)  # -> N, 64, 28, 28\n",
    "        enc4 = self.encoder4(enc3)  # -> N, 128, 14, 14\n",
    "        enc5 = self.encoder5(enc4)  # -> N, 256, 7, 7\n",
    "        \n",
    "        # Decoding with skip connections\n",
    "        dec5 = self.decoder5(enc5)  # -> N, 128, 14, 14\n",
    "        dec4 = self.decoder4(dec5)  # Concatenate encoder4 and decoder5 outputs\n",
    "        dec3 = self.decoder3(torch.cat((dec4, enc3), dim=1))  # -> N, 32, 56, 56\n",
    "        dec2 = self.decoder2(torch.cat((dec3, enc2), dim=1))  # -> N, 16, 112, 112\n",
    "        dec1 = self.decoder1(torch.cat((dec2, enc1), dim=1))  # -> N, 3, 224, 224\n",
    "        \n",
    "        return dec1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "630e05fb-aee6-4f64-bd6b-25d6fa9670aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model=UNetAutoencoder()\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "#device = torch.device(\"cpu\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4599664-9274-4c3d-ab80-dc85033d036e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#x= torch.ones((64,3,224,224))\n",
    "#model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c8e7196-63e9-4049-965e-fe107d588553",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.MSELoss()  # Mean Squared Error loss for autoencoder\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_autoencoder(model, num_epochs, train_dl, valid_dl, patience):\n",
    "    train_loss_hist = [0] * num_epochs\n",
    "    valid_loss_hist = [0] * num_epochs\n",
    "    patience_counter = 0\n",
    "    best_model_wts = model.state_dict()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x_batch, _ in train_dl:\n",
    "            x_batch = x_batch.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(x_batch)\n",
    "            loss = loss_fn(outputs, x_batch)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * x_batch.size(0)\n",
    "\n",
    "        # Calculate average training loss\n",
    "        train_loss /= len(train_dl.dataset)\n",
    "        train_loss_hist[epoch] = train_loss\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x_batch, _ in valid_dl:\n",
    "                x_batch = x_batch.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(x_batch)\n",
    "                loss = loss_fn(outputs, x_batch)\n",
    "\n",
    "                valid_loss += loss.item() * x_batch.size(0)\n",
    "\n",
    "        # Calculate average validation loss\n",
    "        valid_loss /= len(valid_dl.dataset)\n",
    "        valid_loss_hist[epoch] = valid_loss\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_duration = end_time - start_time\n",
    "\n",
    "        # Early Stopping\n",
    "        if epoch > 0 and valid_loss_hist[epoch] > min(valid_loss_hist[:epoch]):\n",
    "            patience_counter += 1\n",
    "        else:\n",
    "            patience_counter = 0\n",
    "            best_model_wts = model.state_dict()\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            model.load_state_dict(best_model_wts)\n",
    "            break\n",
    "\n",
    "        # Epoch Summary\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} Summary:\")\n",
    "        print(f\"  Training - Loss: {train_loss_hist[epoch]:.4f}\")\n",
    "        print(f\"  Validation - Loss: {valid_loss_hist[epoch]:.4f}\")\n",
    "        print(f\"  Duration: {epoch_duration:.2f}s\")\n",
    "\n",
    "    return train_loss_hist, valid_loss_hist\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 50\n",
    "train_loss_hist, valid_loss_hist = train_autoencoder(model, num_epochs, train_loader, val_loader, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5df0135f-bdb4-44cb-871c-7750d080f930",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "x_arr = np.arange(len(train_loss_hist)) + 1\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(x_arr, train_loss_hist, '-o', label='Train loss')\n",
    "ax.plot(x_arr, valid_loss_hist, '--<', label='Validation loss')\n",
    "ax.set_xlabel('Epoch', size=15)\n",
    "ax.set_ylabel('Loss', size=15)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e97745a-5fee-4eec-aa9e-437000c1e19b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to display images\n",
    "def denormalize(tensor):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    return tensor * std + mean\n",
    "def imshow(img, ax):\n",
    "    img = denormalize(img)\n",
    "    npimg = img.numpy()\n",
    "    ax.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# Get a batch of images from the no_defect_val_loader\n",
    "dataiter = iter(test_loader)\n",
    "validation_images, _ = next(dataiter)\n",
    "\n",
    "# Move the images to the device\n",
    "validation_images = validation_images.to(device)\n",
    "\n",
    "# Get the reconstructed images\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    reconstructed = model(validation_images)\n",
    "\n",
    "# Move the images back to CPU for plotting\n",
    "validation_images = validation_images.cpu()\n",
    "reconstructed = reconstructed.cpu()\n",
    "\n",
    "# Plot the original and reconstructed images\n",
    "fig, axes = plt.subplots(nrows=2, ncols=6, figsize=(12, 4))\n",
    "\n",
    "for i in range(6):\n",
    "    # Original images\n",
    "    ax = axes[0, i]\n",
    "    imshow(validation_images[i], ax)\n",
    "    ax.axis('off')\n",
    "    if i == 0:\n",
    "        ax.set_title('Original')\n",
    "\n",
    "    # Reconstructed images\n",
    "    ax = axes[1, i]\n",
    "    imshow(reconstructed[i], ax)\n",
    "    ax.axis('off')\n",
    "    if i == 0:\n",
    "        ax.set_title('Reconstructed')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d732e40-9199-4c19-8f52-8ff46e4c0656",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "\n",
    "# Filter images and labels to include only label 7\n",
    "faulty_indices = [i for i, label in enumerate(labels) if label != 7]\n",
    "print(faulty_indices)\n",
    "print(len(images))\n",
    "faulty_images = [images[i] for i in faulty_indices]\n",
    "faulty_labels = [labels[i] for i in faulty_indices]\n",
    "\n",
    "faulty_subset = LeadIngotDataset(faulty_images, faulty_labels, transform=transform)\n",
    "\n",
    "# Create a DataLoader for the faulty subset\n",
    "faulty_loader = DataLoader(faulty_subset, batch_size=6, shuffle=False)\n",
    "\n",
    "# Get a batch of images from the no_defect_val_loader\n",
    "dataiter = iter(faulty_loader)\n",
    "faulty_images_val, _ = next(dataiter)\n",
    "\n",
    "# Move the images to the device\n",
    "faulty_images_val = faulty_images_val.to(device)\n",
    "\n",
    "# Get the reconstructed images\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    reconstructed = model(faulty_images_val)\n",
    "\n",
    "# Move the images back to CPU for plotting\n",
    "faulty_images_val = faulty_images_val.cpu()\n",
    "reconstructed = reconstructed.cpu()\n",
    "\n",
    "# Plot the original and reconstructed images\n",
    "fig, axes = plt.subplots(nrows=2, ncols=6, figsize=(12, 4))\n",
    "\n",
    "for i in range(6):\n",
    "    # Original images\n",
    "    ax = axes[0, i]\n",
    "    imshow(faulty_images_val[i], ax)\n",
    "    ax.axis('off')\n",
    "    if i == 0:\n",
    "        ax.set_title('Original')\n",
    "\n",
    "    # Reconstructed images\n",
    "    ax = axes[1, i]\n",
    "    imshow(reconstructed[i], ax)\n",
    "    ax.axis('off')\n",
    "    if i == 0:\n",
    "        ax.set_title('Reconstructed')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "UnetAutoencoder Lead",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "env_umicore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
