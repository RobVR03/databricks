{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "139dca48-5cbd-472e-bae1-4e8bba356762",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pathlib\n",
    "import tempfile\n",
    "import time\n",
    "import copy\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1395a2c8-b320-4f61-b259-7ab6aa92db11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "193cc4ca-f5aa-456d-bead-3f300ac85a72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "\n",
    "# Force garbage collection\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aaa7587d-12d0-43c1-b237-52a37fec6862",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "BASE_DIR= pathlib.Path('/Volumes/pmr_dev/lead_ingots/lead_ingot_images')\n",
    "image_dir= BASE_DIR / 'Ingot'\n",
    "label_dir= BASE_DIR / 'Labels/Labels.csv'\n",
    "df = pd.read_csv(label_dir)\n",
    "display(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed8821ad-3ad4-402b-b18e-a1d0388f327f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_names=df[\"Image\"].tolist()\n",
    "print(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccfd48b3-08d1-4417-9ce1-41f6c860591b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load all images at once\n",
    "def load_images(image_names):\n",
    "    images = []\n",
    "    for image_name in image_names:\n",
    "        image_path = image_dir / image_name\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        images.append(image)\n",
    "    return images\n",
    "# Load all images\n",
    "images = load_images(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de822bc1-9b82-466d-b8ad-1752da8beb75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Custom Dataset Class\n",
    "class LeadIngotDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.labels = labels\n",
    "        self.images = images  \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d08af588-4f56-4881-a42f-1a10b5368130",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((1024, 256)), #alexnet, vgg16 input size\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7626549d-0564-4a28-8919-03d00ddd7a6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "new_df = df[[\"Image\", \"Goede blok\"]]\n",
    "new_df.columns = ['Image', 'label']\n",
    "\n",
    "# Replace boolean or string values with integers\n",
    "new_df['label'] = new_df['label'].replace({True: 1, False: 0})\n",
    "\n",
    "print(new_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a47b20f4-1f19-4ead-8c2b-be375b915eda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "labels = new_df['label']\n",
    "ds = LeadIngotDataset(images, labels, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84e9080a-ff0c-4893-9869-c0f35f3c91bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the augmentation transforms\n",
    "augmentation_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally\n",
    "    transforms.RandomVerticalFlip(),  # Randomly flip images vertically\n",
    "    transforms.ToTensor()  # Convert images to tensor\n",
    "])\n",
    "to_pil = transforms.ToPILImage()\n",
    "# Augment images labeled as '0' (Slecht)\n",
    "def augment_data(dataset, labels, num_augmentations=5):\n",
    "    augmented_images = []\n",
    "    augmented_labels = []\n",
    "    for i in range(len(dataset)):\n",
    "        if labels[i] == 0:  # Only augment the images with label '0'\n",
    "            image, label = dataset[i]\n",
    "            \n",
    "            # Generate augmentations\n",
    "            for _ in range(num_augmentations):\n",
    "                augmented_image = augmentation_transforms(to_pil(image))  # Apply the augmentation transforms\n",
    "                augmented_images.append(augmented_image)\n",
    "                augmented_labels.append(label)\n",
    "    return augmented_images, augmented_labels\n",
    "\n",
    "# Split dataset into train, validation, and test\n",
    "train_val_indices, test_indices = train_test_split(\n",
    "    range(len(ds)), test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# Then split train+val into train and validation sets\n",
    "train_indices, val_indices = train_test_split(\n",
    "    train_val_indices, test_size=0.125, stratify=[labels[i] for i in train_val_indices], random_state=42\n",
    ")\n",
    "\n",
    "# Create Subset datasets for training, validation, and test\n",
    "goede_train_dataset = Subset(ds, train_indices)\n",
    "goede_val_dataset = Subset(ds, val_indices)\n",
    "goede_test_dataset = Subset(ds, test_indices)\n",
    "\n",
    "# Apply data augmentation on 'Slecht' class (label 0) for training set only\n",
    "train_images, train_labels = [], []\n",
    "for i in train_indices:\n",
    "    train_images.append(ds[i][0])\n",
    "    train_labels.append(labels[i])\n",
    "\n",
    "augmented_images, augmented_labels = augment_data(goede_train_dataset, train_labels, num_augmentations=0)\n",
    "\n",
    "# Combine augmented images with the original training images\n",
    "combined_train_images = train_images + augmented_images\n",
    "combined_train_labels = train_labels + augmented_labels\n",
    "\n",
    "# Create a new augmented dataset for training\n",
    "augmented_train_dataset = LeadIngotDataset(combined_train_images, combined_train_labels, transform=None)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(augmented_train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(goede_val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(goede_test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "# Print statistics\n",
    "train_labels = [labels[i] for i in train_indices]\n",
    "val_labels = [labels[i] for i in val_indices]\n",
    "test_labels = [labels[i] for i in test_indices]\n",
    "\n",
    "print(f\"Train set size: {len(augmented_train_dataset)} frequenties: {torch.bincount(torch.tensor(combined_train_labels))}\")\n",
    "print(f\"Validation set size: {len(goede_val_dataset)} frequenties: {torch.bincount(torch.tensor(val_labels))}\")\n",
    "print(f\"Test set size: {len(goede_test_dataset)} frequenties: {torch.bincount(torch.tensor(test_labels))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7541336b-e5cc-4acb-8183-943fc505f5ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class simpleCNN (torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simpleCNN, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            torch.nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.fc1 = torch.nn.Linear(256 * 32 * 8, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 2)\n",
    "        self.max_pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "630e05fb-aee6-4f64-bd6b-25d6fa9670aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model=simpleCNN()\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4599664-9274-4c3d-ab80-dc85033d036e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "x= torch.ones((32,3,1024,256))\n",
    "x=x.to(device)\n",
    "print(model(x).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edab716e-daf4-4a6c-9369-1d428c6da4a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_allocated()/1000000000)  # Print the allocated memory\n",
    "print(torch.cuda.memory_reserved()/1000000000)   # Print the reserved memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c8e7196-63e9-4049-965e-fe107d588553",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train(model, num_epochs, train_dl, valid_dl, patience):\n",
    "    loss_hist_train = [0] * num_epochs\n",
    "    accuracy_hist_train = [0] * num_epochs\n",
    "    loss_hist_valid = [0] * num_epochs\n",
    "    accuracy_hist_valid = [0] * num_epochs\n",
    "    patience_counter = 0\n",
    "    best_model_wts = model.state_dict()  # Initialize best model weights\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        \n",
    "        running_loss_train = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        # Training loop\n",
    "        for x_batch, y_batch in train_dl:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Zero gradients\n",
    "            pred = model(x_batch)  # Forward pass\n",
    "            loss = loss_fn(pred, y_batch)  # Calculate loss\n",
    "\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Optimize weights\n",
    "\n",
    "            running_loss_train += loss.item() * y_batch.size(0)\n",
    "            is_correct = (torch.argmax(pred, dim=1) == y_batch).float()\n",
    "            correct_train += is_correct.sum().cpu()\n",
    "            total_train += y_batch.size(0)\n",
    "\n",
    "        loss_hist_train[epoch] = running_loss_train / total_train\n",
    "        accuracy_hist_train[epoch] = correct_train / total_train\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()  # Set to evaluation mode\n",
    "        running_loss_valid = 0.0\n",
    "        correct_valid = 0\n",
    "        total_valid = 0\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient computation\n",
    "            for x_batch, y_batch in valid_dl:\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                pred = model(x_batch)\n",
    "                loss = loss_fn(pred, y_batch)\n",
    "\n",
    "                running_loss_valid += loss.item() * y_batch.size(0)\n",
    "                is_correct = (torch.argmax(pred, dim=1) == y_batch).float()\n",
    "                correct_valid += is_correct.sum().cpu()\n",
    "                total_valid += y_batch.size(0)\n",
    "\n",
    "        loss_hist_valid[epoch] = running_loss_valid / total_valid\n",
    "        accuracy_hist_valid[epoch] = correct_valid / total_valid\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_duration = end_time - start_time\n",
    "\n",
    "        # Early stopping mechanism\n",
    "        if epoch > 0 and loss_hist_valid[epoch] > min(loss_hist_valid[:epoch]):\n",
    "            patience_counter += 1\n",
    "        else:\n",
    "            patience_counter = 0\n",
    "            best_model_wts = model.state_dict()  # Save the best model weights\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            model.load_state_dict(best_model_wts)  # Load the best model weights\n",
    "            break\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} - '\n",
    "              f'Train Loss: {loss_hist_train[epoch]:.4f}, '\n",
    "              f'Train Accuracy: {accuracy_hist_train[epoch]:.4f}, '\n",
    "              f'Val Loss: {loss_hist_valid[epoch]:.4f}, '\n",
    "              f'Val Accuracy: {accuracy_hist_valid[epoch]:.4f}, '\n",
    "              f'Duration: {epoch_duration:.2f}s')\n",
    "\n",
    "    return loss_hist_train, loss_hist_valid, accuracy_hist_train, accuracy_hist_valid\n",
    "\n",
    "\n",
    "num_epochs = 300\n",
    "hist = train(model, num_epochs, train_loader, val_loader, patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5f419f7-726d-4ef3-9e30-ee7be70dbc22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# # Loss and optimizer setup\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# def overfit_single_batch(model, num_epochs, train_dl):\n",
    "#     # Get a single batch from the training data\n",
    "#     x_batch, y_batch = next(iter(train_dl))  # Take one batch\n",
    "#     x_batch = x_batch.to(device)\n",
    "#     y_batch = y_batch.to(device)\n",
    "    \n",
    "#     # Training loop (overfitting on the single batch)\n",
    "#     for epoch in range(num_epochs):\n",
    "#         start_time = time.time()\n",
    "#         model.train()\n",
    "\n",
    "#         optimizer.zero_grad()  # Zero gradients\n",
    "#         pred = model(x_batch)  # Forward pass\n",
    "#         loss = loss_fn(pred, y_batch)  # Compute loss\n",
    "\n",
    "#         loss.backward()  # Backpropagate\n",
    "#         optimizer.step()  # Update weights\n",
    "\n",
    "#         # Print the loss for each epoch\n",
    "#         print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "#         end_time = time.time()\n",
    "#         epoch_duration = end_time - start_time\n",
    "#         print(f\"Epoch Duration: {epoch_duration:.2f}s\")\n",
    "\n",
    "#     return model\n",
    "\n",
    "\n",
    "# num_epochs = 100\n",
    "# model = overfit_single_batch(model, num_epochs, train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "867711ea-d952-4a27-91de-18fcca0ef354",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'CNN.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6551b2b-7e32-42d2-9533-57248fc39b15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = simpleCNN().to(device)\n",
    "model.load_state_dict(torch.load('CNN.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5df0135f-bdb4-44cb-871c-7750d080f930",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Zet het model in evaluatiemodus\n",
    "model.eval()\n",
    "\n",
    "# Lijsten om de echte labels en voorspellingen op te slaan\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "# Geen gradientberekeningen nodig tijdens evaluatie\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in test_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        # Voorspellingen maken\n",
    "        preds = model(x_batch)\n",
    "        preds = torch.argmax(preds, dim=1)\n",
    "        \n",
    "        # Voeg de echte labels en voorspellingen toe aan de lijsten\n",
    "        all_labels.extend(y_batch.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "# Genereer het classificatierapport\n",
    "report = classification_report(all_labels, all_preds, target_names=['Slecht', 'Goed'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ca0b0b6-7dac-4ae9-9008-84ac686b5807",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Define the transformation for the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((1024, 256)),  # Resizing the image\n",
    "    transforms.ToTensor()            # Convert image to tensor\n",
    "])\n",
    "\n",
    "# Custom Dataset class to load images and make predictions\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, image_path  # Return image and its path\n",
    "import torch.nn as nn\n",
    "class simpleCNN (torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simpleCNN, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            torch.nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.fc1 = torch.nn.Linear(256 * 32 * 8, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 2)\n",
    "        self.max_pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "    \n",
    "        return x\n",
    "# Load the model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = simpleCNN().to(device)\n",
    "model.load_state_dict(torch.load('CNN.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Path to the folder with images\n",
    "image_folder = '/Volumes/pmr_dev/lead_ingots/lead_ingot_images/Ingot/Export20241129/'\n",
    "\n",
    "# Get all image paths in the folder\n",
    "image_paths = [os.path.join(image_folder, fname) for fname in os.listdir(image_folder) if fname.endswith(('jpg', 'png', 'jpeg'))]\n",
    "\n",
    "# Create dataset and dataloader for image evaluation\n",
    "dataset = ImageDataset(image_paths, transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# List to store images labeled as '0' (Slecht)\n",
    "slecht_images = []\n",
    "\n",
    "# Make predictions for each image\n",
    "with torch.no_grad():\n",
    "    for x_batch, image_paths_batch in dataloader:\n",
    "        x_batch = x_batch.to(device)\n",
    "\n",
    "        # Get model predictions\n",
    "        preds = model(x_batch)\n",
    "        preds = torch.argmax(preds, dim=1)\n",
    "\n",
    "        # Add the images labeled as '0' (Slecht) to the list\n",
    "        for i, pred in enumerate(preds):\n",
    "            if pred.item() == 0:  # Label '0' corresponds to 'Slecht'\n",
    "                slecht_images.append(image_paths_batch[i])\n",
    "                print(image_paths_batch[i])\n",
    "\n",
    "# Output the list of 'Slecht' images\n",
    "print(\"Images labeled as 'Slecht' (0):\")\n",
    "for image_path in slecht_images:\n",
    "    print(image_path)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "CNN",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "env_umicore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
