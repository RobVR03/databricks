{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "139dca48-5cbd-472e-bae1-4e8bba356762",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pathlib\n",
    "import tempfile\n",
    "import time\n",
    "import copy\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aaa7587d-12d0-43c1-b237-52a37fec6862",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "BASE_DIR= pathlib.Path('/Volumes/pmr_dev/lead_ingots/lead_ingot_images')\n",
    "image_dir= BASE_DIR / 'Ingot'\n",
    "label_dir= BASE_DIR / 'Labels/Labels.csv'\n",
    "df = pd.read_csv(label_dir)\n",
    "display(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed8821ad-3ad4-402b-b18e-a1d0388f327f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_names=df[\"Image\"].tolist()\n",
    "print(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccfd48b3-08d1-4417-9ce1-41f6c860591b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load all images at once\n",
    "def load_images(image_names):\n",
    "    images = []\n",
    "    for image_name in image_names:\n",
    "        image_path = image_dir / image_name\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        images.append(image)\n",
    "    return images\n",
    "# Load all images\n",
    "images = load_images(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d92cd5c-2df3-4904-a460-71548ed421e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the function to encode labels\n",
    "def encode_labels(file_list):\n",
    "    # Extract image names\n",
    "    image_names = file_list['Image']\n",
    "    \n",
    "    # Combine fault categories into a single label\n",
    "    # Create a label string by concatenating fault category names where the value is True\n",
    "    labels = file_list.drop(columns=['Image']).apply(\n",
    "        lambda row: '_'.join(row.index[row == True]), axis=1\n",
    "    )\n",
    "    \n",
    "    # Encode the labels using LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    encoded_labels = le.fit_transform(labels)\n",
    "    \n",
    "    # Create a dictionary mapping image names to encoded labels\n",
    "    label_dict = dict(zip(image_names, encoded_labels))\n",
    "\n",
    "    label_mapping = dict(zip(le.transform(le.classes_),le.classes_ ))\n",
    "    \n",
    "    return label_dict, label_mapping\n",
    "\n",
    "# Encode the labels\n",
    "label_dict, label_mapping = encode_labels(df)\n",
    "\n",
    "for fault_category, label_number in label_mapping.items():\n",
    "    print(f\"{label_number}: {fault_category}\")\n",
    "\n",
    "value_to_find =\"Goede blok\"\n",
    "Goed_label = next((k for k, v in label_mapping.items() if v == value_to_find), None)\n",
    "print(Goed_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4110738-cbf7-46d4-b3f7-8169410306ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "label_counts= [0]*len(label_mapping)\n",
    "for name, label in label_dict.items():\n",
    "    label_counts[label] += 1\n",
    "for i, count in enumerate(label_counts):\n",
    "    print(f\"{label_mapping[i]}: {count}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ac11271-371b-49bb-a074-ebc2cfc118e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de822bc1-9b82-466d-b8ad-1752da8beb75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Custom Dataset Class\n",
    "class LeadIngotDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.labels = labels\n",
    "        self.images = images  \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d08af588-4f56-4881-a42f-1a10b5368130",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((2048, 512)), #alexnet, vgg16 input size\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d109c6a-df06-45f7-a420-586b4915313c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "labels = [label_dict[img] for img in file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84e9080a-ff0c-4893-9869-c0f35f3c91bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "batch_size= 32\n",
    "\n",
    "# Filter images and labels to include only label 7\n",
    "filtered_indices = [i for i, label in enumerate(labels) if label == Goed_label]\n",
    "filtered_images = [images[i] for i in filtered_indices]\n",
    "filtered_labels = [labels[i] for i in filtered_indices]\n",
    "\n",
    "goede_dataset = LeadIngotDataset(filtered_images,filtered_labels, transform)\n",
    "\n",
    "train_val_indices, test_indices = train_test_split(\n",
    "    range(len(goede_dataset)), test_size=0.2, stratify=filtered_labels, random_state=42\n",
    ")\n",
    "\n",
    "# Then split train+val into train and validation sets\n",
    "train_indices, val_indices = train_test_split(\n",
    "    train_val_indices, test_size=0.125, stratify=[filtered_labels[i] for i in train_val_indices], random_state=42\n",
    ")\n",
    "\n",
    "# Create Subset datasets\n",
    "goede_train_dataset = Subset(goede_dataset, train_indices)\n",
    "goede_val_dataset = Subset(goede_dataset, val_indices)\n",
    "goede_test_dataset = Subset(goede_dataset, test_indices)\n",
    "\n",
    "# Create DataLoaders\n",
    "goede_train_loader = DataLoader(goede_train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "goede_val_loader = DataLoader(goede_val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "goede_test_loader = DataLoader(goede_test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "goede_loader = DataLoader(goede_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "# Print statistics\n",
    "train_labels = [filtered_labels[i] for i in train_indices]\n",
    "val_labels = [filtered_labels[i] for i in val_indices]\n",
    "test_labels = [filtered_labels[i] for i in test_indices]\n",
    "\n",
    "print(f\"Train set size: {len(goede_train_dataset)} frequenties: {torch.bincount(torch.tensor(train_labels))}\")\n",
    "print(f\"Validation set size: {len(goede_val_dataset)} frequenties: {torch.bincount(torch.tensor(val_labels))}\")\n",
    "print(f\"Test set size: {len(goede_test_dataset)} frequenties: {torch.bincount(torch.tensor(test_labels))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7541336b-e5cc-4acb-8183-943fc505f5ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            # Level 1\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Level 2\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Level 3\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_mu = nn.Linear(16384, 50)  # Mean of the latent space\n",
    "        self.fc_logvar = nn.Linear(16384, 50)  # Log-variance of the latent space\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.flatten(x)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(50, 16384)  # Map latent space back to feature space\n",
    "        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(256, 256, 64))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 3, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid(),  # Scale output to [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.unflatten(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)  # Sample epsilon ~ N(0, 1)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, mu, logvar\n",
    "\n",
    "# Loss Function for VAE\n",
    "def vae_loss(recon_x, x, mu, logvar):\n",
    "    # Reconstruction Loss\n",
    "    recon_loss = F.mse_loss(recon_x, x, reduction='sum')\n",
    "    # KL Divergence\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + kl_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "630e05fb-aee6-4f64-bd6b-25d6fa9670aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model=VAE()\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "#device = torch.device(\"cpu\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c8e7196-63e9-4049-965e-fe107d588553",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.MSELoss()  # Mean Squared Error loss for autoencoder\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_autoencoder(model, num_epochs, train_dl, valid_dl, patience):\n",
    "    train_loss_hist = [0] * num_epochs\n",
    "    valid_loss_hist = [0] * num_epochs\n",
    "    patience_counter = 0\n",
    "    best_model_wts = model.state_dict()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x_batch, _ in train_dl:\n",
    "            x_batch = x_batch.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(x_batch)\n",
    "            loss = loss_fn(outputs, x_batch)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * x_batch.size(0)\n",
    "\n",
    "        # Calculate average training loss\n",
    "        train_loss /= len(train_dl.dataset)\n",
    "        train_loss_hist[epoch] = train_loss\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x_batch, _ in valid_dl:\n",
    "                x_batch = x_batch.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(x_batch)\n",
    "                loss = loss_fn(outputs, x_batch)\n",
    "\n",
    "                valid_loss += loss.item() * x_batch.size(0)\n",
    "\n",
    "        # Calculate average validation loss\n",
    "        valid_loss /= len(valid_dl.dataset)\n",
    "        valid_loss_hist[epoch] = valid_loss\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_duration = end_time - start_time\n",
    "\n",
    "        # Early Stopping\n",
    "        if epoch > 0 and valid_loss_hist[epoch] > min(valid_loss_hist[:epoch]):\n",
    "            patience_counter += 1\n",
    "        else:\n",
    "            patience_counter = 0\n",
    "            best_model_wts = model.state_dict()\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            model.load_state_dict(best_model_wts)\n",
    "            break\n",
    "\n",
    "        # Epoch Summary\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} Summary:\")\n",
    "        print(f\"  Training - Loss: {train_loss_hist[epoch]:.4f}\")\n",
    "        print(f\"  Validation - Loss: {valid_loss_hist[epoch]:.4f}\")\n",
    "        print(f\"  Duration: {epoch_duration:.2f}s\")\n",
    "\n",
    "    return train_loss_hist, valid_loss_hist\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 1000\n",
    "train_loss_hist, valid_loss_hist = train_autoencoder(model, num_epochs, goede_train_loader, goede_val_loader, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "867711ea-d952-4a27-91de-18fcca0ef354",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'VAE.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6551b2b-7e32-42d2-9533-57248fc39b15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = VAE().to(device)\n",
    "model.load_state_dict(torch.load('VAE.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5df0135f-bdb4-44cb-871c-7750d080f930",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "x_arr = np.arange(len(train_loss_hist)) + 1\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(x_arr, train_loss_hist, '-o', label='Train loss')\n",
    "ax.plot(x_arr, valid_loss_hist, '--<', label='Validation loss')\n",
    "ax.set_xlabel('Epoch', size=15)\n",
    "ax.set_ylabel('Loss', size=15)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "257221a5-b30a-4602-8758-b48250a3ed21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter images and labels to include only label 8\n",
    "faulty_indices = [i for i, label in enumerate(labels) if label != Goed_label]\n",
    "faulty_images = [images[i] for i in faulty_indices]\n",
    "faulty_labels = [labels[i] for i in faulty_indices]\n",
    "faulty_subset = LeadIngotDataset(faulty_images, faulty_labels, transform=transform)\n",
    "\n",
    "# Create a DataLoader for the no_faulty subset\n",
    "faulty_loader = DataLoader(faulty_subset, batch_size=6, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ca4d380-7705-4ef6-b410-3b874dd39bb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "len(faulty_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e97745a-5fee-4eec-aa9e-437000c1e19b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "resize_transform = transforms.Resize((500, 1880))\n",
    "# Function to display images\n",
    "def denormalize(tensor):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    return tensor * std + mean\n",
    "def imshow(img, ax):\n",
    "    #img = denormalize(img)\n",
    "    img=resize_transform(img)\n",
    "    npimg = img.numpy()\n",
    "    ax.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# Get a batch of images from the no_defect_val_loader\n",
    "dataiter = iter(goede_test_loader)\n",
    "print(len(dataiter))\n",
    "validation_images, _ = next(dataiter)\n",
    "\n",
    "# Move the images to the device\n",
    "validation_images = validation_images.to(device)\n",
    "\n",
    "# Get the reconstructed images\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    reconstructed = model(validation_images)\n",
    "\n",
    "# Move the images back to CPU for plotting\n",
    "validation_images = validation_images.cpu()\n",
    "reconstructed = reconstructed.cpu()\n",
    "\n",
    "# Plot the original and reconstructed images\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(24, 8))\n",
    "\n",
    "for i in range(3):\n",
    "    # Original images\n",
    "    ax = axes[0, i]\n",
    "    imshow(validation_images[i], ax)\n",
    "    ax.axis('off')\n",
    "    if i == 0:\n",
    "        ax.set_title('Original')\n",
    "\n",
    "    # Reconstructed images\n",
    "    ax = axes[1, i]\n",
    "    imshow(reconstructed[i], ax)\n",
    "    ax.axis('off')\n",
    "    if i == 0:\n",
    "        ax.set_title('Reconstructed')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86865201-8036-42d1-afae-8621b3296fed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "# Get a batch of images from the no_defect_val_loader\n",
    "dataiter2 = iter(faulty_loader)\n",
    "faulty_images_val, _ = next(dataiter2)\n",
    "\n",
    "# Move the images to the device\n",
    "faulty_images_val = faulty_images_val.to(device)\n",
    "\n",
    "# Get the reconstructed images\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    reconstructed = model(faulty_images_val)\n",
    "\n",
    "# Move the images back to CPU for plotting\n",
    "faulty_images_val = faulty_images_val.cpu()\n",
    "reconstructed = reconstructed.cpu()\n",
    "\n",
    "# Plot the original and reconstructed images\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(24, 8))\n",
    "\n",
    "for i in range(3):\n",
    "    # Original images\n",
    "    ax = axes[0, i]\n",
    "    imshow(faulty_images_val[i], ax)\n",
    "    ax.axis('off')\n",
    "    if i == 0:\n",
    "        ax.set_title('Original')\n",
    "\n",
    "    # Reconstructed images\n",
    "    ax = axes[1, i]\n",
    "    imshow(reconstructed[i], ax)\n",
    "    ax.axis('off')\n",
    "    if i == 0:\n",
    "        ax.set_title('Reconstructed')\n",
    "\n",
    "plt.show()\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Calculate reconstruction errors\n",
    "reconstruction_errors = F.mse_loss(reconstructed, faulty_images_val, reduction='none')\n",
    "reconstruction_errors = reconstruction_errors.mean(dim=[1, 2, 3])\n",
    "print(reconstruction_errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "698f2bb2-5664-46fa-9296-0051c2750179",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "# Function to calculate reconstruction errors\n",
    "def calculate_reconstruction_errors(loader):\n",
    "    all_errors = []\n",
    "    for images, _ in loader:\n",
    "        images = images.to(device)\n",
    "        with torch.no_grad():\n",
    "            reconstructed = model(images)\n",
    "        images = images.cpu()\n",
    "        reconstructed = reconstructed.cpu()\n",
    "        errors = F.mse_loss(reconstructed, images, reduction='none')\n",
    "        errors = errors.mean(dim=[1, 2, 3])\n",
    "        all_errors.extend(errors.numpy())\n",
    "    return all_errors\n",
    "\n",
    "# Calculate reconstruction errors for faulty and no_faulty images\n",
    "faulty_errors = calculate_reconstruction_errors(faulty_loader)\n",
    "no_faulty_errors = calculate_reconstruction_errors(goede_loader)\n",
    "\n",
    "# Plot the reconstruction errors\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(faulty_errors, bins=30, alpha=0.5, label='Faulty')\n",
    "plt.hist(no_faulty_errors, bins=30, alpha=0.5, label='No Faulty')\n",
    "plt.xlabel('Reconstruction Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.title('Reconstruction Errors for Faulty and No Faulty Images')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b006e08-fba0-45e4-bf2f-0e8d0ce16970",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Zet je model in eval-mode\n",
    "model.eval()\n",
    "\n",
    "# Lijst voor de latente representaties en de bijbehorende labels\n",
    "latent_representations = []\n",
    "\n",
    "\n",
    "# Functie om latente ruimte te extraheren uit beide dataloaders\n",
    "def extract_latent_space(dataloader, category_label):\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            inputs, _ = data  # Neem de inputs, labels zijn niet nodig voor latente ruimte\n",
    "            inputs = inputs.to(device)  # Zet de data op het juiste apparaat\n",
    "\n",
    "            # Haal de latente representatie op\n",
    "            encoded = model.encoder(inputs)\n",
    "            encoded = encoded.view(encoded.size(0), -1)  # Flatten de latente ruimte\n",
    "\n",
    "            # Voeg de latente representatie toe aan de lijst, samen met de label\n",
    "            latent_representations.append(encoded.cpu().numpy())\n",
    "\n",
    "\n",
    "# Veronderstel dat de dataloaders dataloaders1 en dataloaders2 de verschillende categorieën bevatten\n",
    "extract_latent_space(goede_loader, category_label=0)  # Categorie 1\n",
    "extract_latent_space(faulty_loader, category_label=1)  # Categorie 2\n",
    "\n",
    "# Zet de latente representaties om naar een numpy array\n",
    "latent_representations = np.vstack(latent_representations)\n",
    "\n",
    "# Stap 3: Dimensionality Reduction (bijv. PCA of t-SNE)\n",
    "\n",
    "# Probeer eerst PCA om de data naar 2D te reduceren\n",
    "pca = PCA(n_components=2)\n",
    "reduced_data = pca.fit_transform(latent_representations)\n",
    "\n",
    "# Je kunt ook t-SNE proberen voor een betere visualisatie\n",
    "# t_sne = TSNE(n_components=2, random_state=42)\n",
    "# reduced_data = t_sne.fit_transform(latent_representations)\n",
    "goede_reduced_data=reduced_data[0:len(goede_loader.dataset)-1]\n",
    "slechte_reduced_data=reduced_data[len(goede_loader.dataset)-1:]\n",
    "\n",
    "# Stap 4: Visualiseer de latente ruimte\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot de verschillende categorieën met verschillende kleuren\n",
    "plt.scatter(goede_reduced_data[:, 0], goede_reduced_data[:, 1], color='r', label='Categorie 1', alpha=0.5)\n",
    "plt.scatter(slechte_reduced_data[:, 0], slechte_reduced_data[:, 1], color='b', label='Categorie 2', alpha=0.5)\n",
    "\n",
    "plt.title('Latente Ruimte (2D weergave)')\n",
    "plt.xlabel('Hoofdbestanddeel 1')\n",
    "plt.ylabel('Hoofdbestanddeel 2')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "VAE",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "env_umicore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
