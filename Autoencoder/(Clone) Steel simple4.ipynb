{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "139dca48-5cbd-472e-bae1-4e8bba356762",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pathlib\n",
    "import tempfile\n",
    "import time\n",
    "import copy\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aaa7587d-12d0-43c1-b237-52a37fec6862",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "BASE_DIR= pathlib.Path('/Volumes/pmr_dev/lead_ingots/lead_ingot_images')\n",
    "\n",
    "image_dir= BASE_DIR / 'Ingot'\n",
    "label_dir= BASE_DIR / 'Labels/Labels.csv'\n",
    "file_list = pd.read_csv(label_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbbbea89-8566-4853-8a29-45e5fc24e33a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(file_list.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d92cd5c-2df3-4904-a460-71548ed421e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the function to encode labels\n",
    "def encode_labels(file_list):\n",
    "    # Extract image names\n",
    "    image_names = file_list['Image']\n",
    "    \n",
    "    # Combine fault categories into a single label\n",
    "    # Create a label string by concatenating fault category names where the value is True\n",
    "    labels = file_list.drop(columns=['Image']).apply(\n",
    "        lambda row: '_'.join(row.index[row == True]), axis=1\n",
    "    )\n",
    "    \n",
    "    # Encode the labels using LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    encoded_labels = le.fit_transform(labels)\n",
    "    \n",
    "    # Create a dictionary mapping image names to encoded labels\n",
    "    label_dict = dict(zip(image_names, encoded_labels))\n",
    "    \n",
    "    return label_dict, le\n",
    "\n",
    "# Encode the labels\n",
    "label_dict, label_encoder = encode_labels(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01b94aba-bcb3-468a-9bec-4f591e2fd1fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Print the mapping of label numbers to fault categories\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Label Number to Fault Category Mapping:\")\n",
    "for fault_category, label_number in label_mapping.items():\n",
    "    print(f\"{label_number}: {fault_category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4110738-cbf7-46d4-b3f7-8169410306ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate and print the frequencies of the different classes\n",
    "label_counts = pd.Series(label_dict.values()).value_counts()\n",
    "print(\"Frequencies of the different classes:\")\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de822bc1-9b82-466d-b8ad-1752da8beb75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Custom Dataset Class\n",
    "class LeadIngotDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.labels = labels\n",
    "        self.images = images  \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8eb8bd9-7db7-4fe3-b62d-b9aa2e7af979",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load all images at once\n",
    "def load_images(image_names):\n",
    "    images = []\n",
    "    for image_name in image_names:\n",
    "        image_path = image_dir / image_name\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        images.append(image)\n",
    "    return images\n",
    "# Load all images\n",
    "image_names = file_list['Image'].tolist()\n",
    "images = load_images(image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d08af588-4f56-4881-a42f-1a10b5368130",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), #alexnet, vgg16 input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) #imagenet noramlization\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d109c6a-df06-45f7-a420-586b4915313c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "labels = [label_dict[img] for img in image_names]\n",
    "dataset = LeadIngotDataset(images, labels, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84e9080a-ff0c-4893-9869-c0f35f3c91bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "batch_size= 32\n",
    "\n",
    "# Filter images and labels to include only label 7\n",
    "filtered_indices = [i for i, label in enumerate(labels) if label == 7]\n",
    "filtered_images = [images[i] for i in filtered_indices]\n",
    "filtered_labels = [labels[i] for i in filtered_indices]\n",
    "\n",
    "dataset = LeadIngotDataset(filtered_images, filtered_labels, transform)\n",
    "\n",
    "train_val_indices, test_indices = train_test_split(\n",
    "    range(len(dataset)), test_size=0.2, stratify=filtered_labels, random_state=42\n",
    ")\n",
    "\n",
    "# Then split train+val into train and validation sets\n",
    "train_indices, val_indices = train_test_split(\n",
    "    train_val_indices, test_size=0.125, stratify=[filtered_labels[i] for i in train_val_indices], random_state=42\n",
    ")\n",
    "\n",
    "# Create Subset datasets\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "# Print statistics\n",
    "train_labels = [filtered_labels[i] for i in train_indices]\n",
    "val_labels = [filtered_labels[i] for i in val_indices]\n",
    "test_labels = [filtered_labels[i] for i in test_indices]\n",
    "\n",
    "print(f\"Train set size: {len(train_dataset)} frequenties: {torch.bincount(torch.tensor(train_labels))}\")\n",
    "print(f\"Validation set size: {len(val_dataset)} frequenties: {torch.bincount(torch.tensor(val_labels))}\")\n",
    "print(f\"Test set size: {len(test_dataset)} frequenties: {torch.bincount(torch.tensor(test_labels))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7541336b-e5cc-4acb-8183-943fc505f5ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        # N, 1, 224, 224\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=2, padding=1), # -> N, 16, 112, 112\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1), # -> N, 32, 56, 56\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1), # -> N, 64, 28, 28\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1), # -> N, 128, 14, 14\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, 3, stride=2, padding=1), # -> N, 256, 7, 7\n",
    "        )\n",
    "        \n",
    "        # N , 64, 1, 1\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1), # -> N, 128, 14, 14\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), # -> N, 64, 28, 28\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), # -> N, 32, 56, 56\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1), # -> N, 16, 112, 112\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 3, 3, stride=2, padding=1, output_padding=1), # -> N, 1, 224, 224\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "630e05fb-aee6-4f64-bd6b-25d6fa9670aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model=Autoencoder()\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "#device = torch.device(\"cpu\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4599664-9274-4c3d-ab80-dc85033d036e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#x= torch.ones((64,3,224,224))\n",
    "#model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c8e7196-63e9-4049-965e-fe107d588553",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch.nn as nn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train(model, num_epochs, train_dl, valid_dl, patience):\n",
    "    loss_hist_train = [0] * num_epochs\n",
    "    accuracy_hist_train = [0] * num_epochs\n",
    "    loss_hist_valid = [0] * num_epochs\n",
    "    accuracy_hist_valid = [0] * num_epochs\n",
    "    patience_counter = 0  # Initialize patience counter\n",
    "    best_model_wts = model.state_dict()  # Initialize best model weights\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        batch_train_count = 0\n",
    "        for x_batch, y_batch in train_dl:\n",
    "            batch_train_count += 1\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            pred = model(x_batch)\n",
    "            loss = loss_fn(pred, y_batch)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Track metrics\n",
    "            loss_hist_train[epoch] += loss.item() * y_batch.size(0)\n",
    "            is_correct = (torch.argmax(pred, dim=1) == y_batch).float()\n",
    "            accuracy_hist_train[epoch] += is_correct.sum().cpu()\n",
    "\n",
    "            if batch_train_count % 10 == 0:  # Print progress every 10 batches\n",
    "                print(f\"  [Training] Batch {batch_train_count}/{len(train_dl)} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # Calculate epoch-level metrics for training\n",
    "        loss_hist_train[epoch] /= len(train_dl.dataset)\n",
    "        accuracy_hist_train[epoch] /= len(train_dl.dataset)\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        batch_valid_count = 0\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in valid_dl:\n",
    "                batch_valid_count += 1\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                pred = model(x_batch)\n",
    "                loss = loss_fn(pred, y_batch)\n",
    "\n",
    "                # Track metrics\n",
    "                loss_hist_valid[epoch] += loss.item() * y_batch.size(0)\n",
    "                is_correct = (torch.argmax(pred, dim=1) == y_batch).float()\n",
    "                accuracy_hist_valid[epoch] += is_correct.sum().cpu()\n",
    "\n",
    "                if batch_valid_count % 10 == 0:  # Print progress every 10 batches\n",
    "                    print(f\"  [Validation] Batch {batch_valid_count}/{len(valid_dl)} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # Calculate epoch-level metrics for validation\n",
    "        loss_hist_valid[epoch] /= len(valid_dl.dataset)\n",
    "        accuracy_hist_valid[epoch] /= len(valid_dl.dataset)\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_duration = end_time - start_time\n",
    "\n",
    "        # Early Stopping\n",
    "        if epoch > 0 and loss_hist_valid[epoch] > min(loss_hist_valid[:epoch]):\n",
    "            patience_counter += 1\n",
    "        else:\n",
    "            patience_counter = 0\n",
    "            best_model_wts = model.state_dict()  # Save the best model weights\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            model.load_state_dict(best_model_wts)  # Load the best model weights\n",
    "            break\n",
    "\n",
    "        # Epoch Summary\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1}/{num_epochs} Summary:\"\n",
    "            f\"\\n  Training - Loss: {loss_hist_train[epoch]:.4f}, Accuracy: {accuracy_hist_train[epoch]:.4f}\"\n",
    "            f\"\\n  Validation - Loss: {loss_hist_valid[epoch]:.4f}, Accuracy: {accuracy_hist_valid[epoch]:.4f}\"\n",
    "            f\"\\n  Duration: {epoch_duration:.2f}s\"\n",
    "        )\n",
    "\n",
    "    return loss_hist_train, loss_hist_valid, accuracy_hist_train, accuracy_hist_valid\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 300\n",
    "hist = train(model, num_epochs, train_loader, val_loader, patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7dc0919-a360-4c2c-9f70-152f8b63a921",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "early_stop_epoch = next((i for i, v in enumerate(hist[0]) if v == 0), len(hist[0]))\n",
    "x_arr = np.arange(len(hist[0])) + 1\n",
    "\n",
    "# Adjust x_arr to stop at early_stop_epoch\n",
    "x_arr = x_arr[:early_stop_epoch]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(x_arr, hist[0][:early_stop_epoch], '-o', label='Train loss')\n",
    "ax.plot(x_arr, hist[1][:early_stop_epoch], '--<', label='Validation loss')\n",
    "ax.set_xlabel('Epoch', size=15)\n",
    "ax.set_ylabel('Loss', size=15)\n",
    "ax.legend(fontsize=15)\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(x_arr, hist[2][:early_stop_epoch], '-o', label='Train acc.')\n",
    "ax.plot(x_arr, hist[3][:early_stop_epoch], '--<', label='Validation acc.')\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_xlabel('Epoch', size=15)\n",
    "ax.set_ylabel('Accuracy', size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d77eff17-afd8-4953-ae03-2f55acea2540",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Zet het model in evaluatiemodus\n",
    "model.eval()\n",
    "\n",
    "# Lijsten om de echte labels en voorspellingen op te slaan\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "# Geen gradientberekeningen nodig tijdens evaluatie\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in test_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        # Voorspellingen maken\n",
    "        preds = model(x_batch)\n",
    "        preds = torch.argmax(preds, dim=1)\n",
    "        \n",
    "        # Voeg de echte labels en voorspellingen toe aan de lijsten\n",
    "        all_labels.extend(y_batch.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "# Genereer het classificatierapport\n",
    "report = classification_report(all_labels, all_preds, target_names=['Crazing', 'Inclusion', 'Patches', 'Pitted', 'Rolled', 'Scratches'])\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "(Clone) Steel simple4",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "env_umicore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
